{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task - 1\n",
        "Text extraction from image"
      ],
      "metadata": {
        "id": "mLQfDmni5zDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q streamlit pymupdf chromadb pyngrok faiss-cpu sentence-transformers mistralai==0.4.2 python-docx\n",
        "\n",
        "# Configuring ngrok authtoken\n",
        "!ngrok config add-authtoken 2xDRF1RvT6YJDp4CJkWMzyp1I65_6yk76D4JxHm1do76eWGb2\n",
        "\n",
        "# Killing previous processes\n",
        "!pkill -f streamlit || echo \"No old Streamlit process\"\n",
        "!pkill -f ngrok || echo \"No old ngrok process\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFOTSD3_HtSm",
        "outputId": "58ca88ba-010c-4c86-fc13-ae744a17926e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import fitz  # PyMuPDF for PDF\n",
        "from docx import Document  # For DOCX\n",
        "import tempfile\n",
        "import os\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "\n",
        "st.set_page_config(page_title=\"RAG Multi-Document Chatbot\", layout=\"wide\")\n",
        "st.title(\"ðŸ¤– RAG Multi-Document Chatbot\")\n",
        "\n",
        "# Sidebar for API key and file uploads\n",
        "st.sidebar.markdown(\"### Configuration\")\n",
        "api_key = st.sidebar.text_input(\"ðŸ”‘ Enter Mistral API Key\", type=\"password\")\n",
        "st.sidebar.markdown(\"---\")\n",
        "uploaded_files = st.sidebar.file_uploader(\n",
        "    \"ðŸ“„ Upload Documents (PDF, DOCX, TXT)\",\n",
        "    type=[\"pdf\", \"docx\", \"txt\"],\n",
        "    accept_multiple_files=True\n",
        ")\n",
        "st.sidebar.markdown(\"---\")\n",
        "process_btn = st.sidebar.button(\"Process Documents\")\n",
        "\n",
        "# Session state\n",
        "if \"db\" not in st.session_state:\n",
        "    st.session_state.db = None\n",
        "if \"chunks\" not in st.session_state:\n",
        "    st.session_state.chunks = []\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "if \"collection_name\" not in st.session_state:\n",
        "    st.session_state.collection_name = \"doc_chunks\"\n",
        "if \"embedder\" not in st.session_state:\n",
        "    st.session_state.embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Function to extract text from different file types\n",
        "def extract_text(file, file_type):\n",
        "    \"\"\"\n",
        "    Extract text from PDF, DOCX, or TXT file.\n",
        "    Returns extracted text or empty string on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=f\".{file_type}\") as tmp:\n",
        "            tmp.write(file.getbuffer())\n",
        "            tmp_path = tmp.name\n",
        "\n",
        "        if file_type == \"pdf\":\n",
        "            with fitz.open(tmp_path) as doc:\n",
        "                if len(doc) == 0:\n",
        "                    st.error(f\"PDF {file.name} is empty or corrupted.\")\n",
        "                    return \"\"\n",
        "                text = \"\".join(page.get_text() for page in doc)\n",
        "        elif file_type == \"docx\":\n",
        "            doc = Document(tmp_path)\n",
        "            text = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "        elif file_type == \"txt\":\n",
        "            with open(tmp_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                text = f.read()\n",
        "        else:\n",
        "            st.error(f\"Unsupported file type: {file_type}\")\n",
        "            return \"\"\n",
        "\n",
        "        os.remove(tmp_path)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error processing {file.name}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def chunk_text(text, chunk_size=2000, overlap=400):\n",
        "    \"\"\"\n",
        "    Split text into chunks with specified size and optional overlap.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + chunk_size, len(text))\n",
        "        chunks.append(text[start:end])\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Document processing\n",
        "if uploaded_files and api_key and process_btn:\n",
        "    with st.spinner(\"Processing Documents...\"):\n",
        "        st.session_state.chunks = []\n",
        "        for i, file in enumerate(uploaded_files):\n",
        "            file_type = file.name.split(\".\")[-1].lower()\n",
        "            doc_label = f\"Document {i+1}: {file.name}\"\n",
        "            if file.size > 10 * 1024 * 1024:  # 10MB size limit\n",
        "                st.warning(f\"Skipping {file.name}: File too large.\")\n",
        "                continue\n",
        "            st.info(f\"Extracting text from {file_type.upper()} {i+1}/{len(uploaded_files)}: {file.name}\")\n",
        "            text = extract_text(file, file_type)\n",
        "            if not text:\n",
        "                continue  # Skip to the next file if text extraction fails\n",
        "            # Chunking with overlap for better context\n",
        "            chunks = chunk_text(text, chunk_size=2000, overlap=400)\n",
        "            labeled_chunks = [f\"[{doc_label}]\\n{chunk}\" for chunk in chunks]\n",
        "            st.session_state.chunks.extend(labeled_chunks)\n",
        "\n",
        "        if not st.session_state.chunks:\n",
        "            st.error(\"No valid content extracted from documents.\")\n",
        "        else:\n",
        "            st.info(f\"Total chunks to embed: {len(st.session_state.chunks)}\")\n",
        "            # Embeddings\n",
        "            embedder = st.session_state.embedder\n",
        "            embeddings = embedder.encode(st.session_state.chunks, show_progress_bar=True)\n",
        "            # ChromaDB (persistent storage)\n",
        "            client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "            # Clean up existing collection\n",
        "            if st.session_state.collection_name in [col.name for col in client.list_collections()]:\n",
        "                client.delete_collection(st.session_state.collection_name)\n",
        "            collection = client.create_collection(st.session_state.collection_name)\n",
        "            # Batch add all chunks and embeddings\n",
        "            ids = [str(i) for i in range(len(st.session_state.chunks))]\n",
        "            collection.add(\n",
        "                documents=st.session_state.chunks,\n",
        "                embeddings=[emb.tolist() for emb in embeddings],\n",
        "                ids=ids\n",
        "            )\n",
        "            st.session_state.db = collection\n",
        "            st.success(f\"Processed {len(uploaded_files)} documents and indexed {len(st.session_state.chunks)} chunks.\")\n",
        "\n",
        "# Chat interface\n",
        "if api_key and st.session_state.db:\n",
        "    for role, msg in st.session_state.history:\n",
        "        with st.chat_message(role):\n",
        "            st.write(msg)\n",
        "    user_input = st.chat_input(\"Ask a question about your documents...\")\n",
        "    if user_input:\n",
        "        if len(user_input.strip()) < 3:\n",
        "            st.warning(\"Please enter a more specific question.\")\n",
        "        else:\n",
        "            try:\n",
        "                embedder = st.session_state.embedder\n",
        "                q_emb = embedder.encode([user_input])[0].tolist()\n",
        "                results = st.session_state.db.query(query_embeddings=[q_emb], n_results=4)\n",
        "                context = \"\\n\\n\".join(results[\"documents\"][0])\n",
        "                client = MistralClient(api_key=api_key)\n",
        "                # Prompt engineering for RAG\n",
        "                system_prompt = (\n",
        "                    \"You are a helpful assistant. When answering, perform all reasoning, outlining, and analysis internally. \"\n",
        "                    \"Only display the final answer to the user, without showing your thought process or intermediate steps. \"\n",
        "                    \"If the context does not contain enough information to answer, say: 'I could not find the answer in the uploaded documents.'\"\n",
        "                    )\n",
        "                chat_history = \"\"\n",
        "                for role, msg in st.session_state.history[-6:]:  # last 3 exchanges (user + assistant)\n",
        "                  speaker = \"User\" if role == \"user\" else \"Assistant\"\n",
        "                  chat_history += f\"{speaker}: {msg}\\n\"\n",
        "                messages = [\n",
        "                    ChatMessage(role=\"system\", content=system_prompt),ChatMessage(role=\"user\",\n",
        "                    content=(\n",
        "                        f\"Context:\\n{context}\\n\\n\"\n",
        "                        f\"Chat History:\\n{chat_history}\\n\"\n",
        "                        f\"User Question: {user_input}\"\n",
        "                        )\n",
        "                    )\n",
        "                    ]\n",
        "                response = client.chat(model=\"mistral-small-latest\", messages=messages)\n",
        "                answer = response.choices[0].message.content\n",
        "                st.session_state.history.append((\"user\", user_input))\n",
        "                st.session_state.history.append((\"assistant\", answer))\n",
        "                # Limit history to last 50 entries (25 exchanges)\n",
        "                if len(st.session_state.history) > 50:\n",
        "                    st.session_state.history = st.session_state.history[-50:]\n",
        "                st.rerun()\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error generating response: {str(e)}\")\n",
        "elif not api_key:\n",
        "    st.info(\"Enter your Mistral API key in the sidebar.\")\n",
        "elif not uploaded_files:\n",
        "    st.info(\"Upload documents (PDF, DOCX, TXT) and click 'Process Documents'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHMZ0mnUCSf",
        "outputId": "f230be92-ec79-4dc8-de90-f2e7999c622e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Start Streamlit\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"])\n",
        "\n",
        "# Wait for Streamlit to start\n",
        "for _ in range(10):\n",
        "    try:\n",
        "        requests.get(\"http://localhost:8501\")\n",
        "        break\n",
        "    except:\n",
        "        time.sleep(1)\n",
        "else:\n",
        "    print(\"Streamlit failed to start\")\n",
        "    process.terminate()\n",
        "    exit(1)\n",
        "\n",
        "# Start ngrok\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"ðŸŒ Your app is live at: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok: {str(e)}\")\n",
        "    process.terminate()\n",
        "    exit(1)\n",
        "\n",
        "import atexit\n",
        "atexit.register(process.terminate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "i6q4rIvCgKZJ",
        "outputId": "1dc7f747-cdd3-42da-9096-a926166b824b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ Your app is live at: NgrokTunnel: \"https://00bd-34-55-248-241.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Popen.terminate of <Popen: returncode: None args: ['streamlit', 'run', 'app.py', '--server.port...>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>subprocess.Popen.terminate</b><br/>def terminate()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/lib/python3.11/subprocess.py</a>Terminate the process with SIGTERM\n",
              "            </pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2208);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DXxlR9gdt5sG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
